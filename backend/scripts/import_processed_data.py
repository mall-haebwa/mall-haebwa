"""
LLMì´ ê°€ê³µí•œ ìƒí’ˆ ë°ì´í„°ë¥¼ MongoDBì— ì„í¬íŠ¸

ì‹¤í–‰ ë°©ë²•:
    # ì „ì²´ ë””ë ‰í† ë¦¬ ì²˜ë¦¬
    python -m backend.scripts.import_processed_data --input-dir ./data_batches/processed
    
    # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
    python -m backend.scripts.import_processed_data --file ./data_batches/processed/processed_0000.json

ê¸°ëŠ¥:
    - LLM ê°€ê³µ ë°ì´í„° + ì›ë³¸ ë°ì´í„° ê²°í•©
    - Rank ê¸°ë°˜ ë¦¬ë·° ìë™ ìƒì„±
    - products_v2 ì»¬ë ‰ì…˜ì— ì €ì¥
"""

import os
import json
import sys
from pymongo import MongoClient
from bson import ObjectId
from datetime import datetime
import random
import argparse


def generate_review_data(rank: int) -> dict:
    """
    Rank ê¸°ë°˜ ë¦¬ë·° ë°ì´í„° ìƒì„±
    
    Args:
        rank: ê²€ìƒ‰ ìˆœìœ„ (1ì´ ìµœìƒìœ„, 999ê°€ ìµœí•˜ìœ„)
    
    Returns:
        {"rating": 4.5, "count": 1240, "isGenerated": True}
    """
    
    if rank <= 10:
        # ìƒìœ„ 10ìœ„: ë² ìŠ¤íŠ¸ì…€ëŸ¬
        rating = round(random.uniform(4.6, 5.0), 1)
        count = random.randint(800, 2500)
        
    elif rank <= 30:
        # 11~30ìœ„: ì¸ê¸° ìƒí’ˆ
        rating = round(random.uniform(4.3, 4.7), 1)
        count = random.randint(400, 800)
        
    elif rank <= 100:
        # 31~100ìœ„: ì¤‘ìƒìœ„ ìƒí’ˆ
        rating = round(random.uniform(4.0, 4.5), 1)
        count = random.randint(150, 400)
        
    elif rank <= 300:
        # 101~300ìœ„: ì¤‘ê°„ ìƒí’ˆ
        rating = round(random.uniform(3.8, 4.3), 1)
        count = random.randint(50, 150)
        
    else:
        # 301ìœ„ ì´ìƒ: í•˜ìœ„ ìƒí’ˆ
        rating = round(random.uniform(3.5, 4.0), 1)
        count = random.randint(10, 50)
    
    return {
        "rating": rating,
        "count": count,
        "isGenerated": True
    }


def import_processed_batch(processed_file: str, db, dry_run=False):
    """
    ê°€ê³µëœ JSON íŒŒì¼ì„ MongoDBì— ì €ì¥
    
    Args:
        processed_file: LLMì´ ê°€ê³µí•œ JSON íŒŒì¼ ê²½ë¡œ
        db: MongoDB database ê°ì²´
        dry_run: Trueë©´ ì‹¤ì œ ì €ì¥í•˜ì§€ ì•Šê³  ì¶œë ¥ë§Œ
    """
    
    products_original = db["products"]
    products_processed = db["products_v2"]
    
    # ê°€ê³µëœ ë°ì´í„° ë¡œë“œ
    print(f"\nğŸ“‚ íŒŒì¼ ë¡œë“œ: {processed_file}")
    
    with open(processed_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    if "products" not in data:
        print(f"âŒ ì˜¤ë¥˜: 'products' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. JSON í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    success_count = 0
    error_count = 0
    
    total = len(data["products"])
    print(f"ğŸ“Š ì²˜ë¦¬í•  ìƒí’ˆ: {total}ê°œ\n")
    
    for idx, item in enumerate(data["products"], 1):
        try:
            # ID í™•ì¸
            if "id" not in item:
                print(f"âš ï¸  [{idx}/{total}] ID ì—†ìŒ - ê±´ë„ˆëœ€")
                error_count += 1
                continue
            
            product_id = ObjectId(item["id"])
            processed_data = item.get("processed", {})
            
            # ì›ë³¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            original = products_original.find_one({"_id": product_id})
            
            if not original:
                print(f"âš ï¸  [{idx}/{total}] ì›ë³¸ ë°ì´í„° ì—†ìŒ: {product_id}")
                error_count += 1
                continue
            
            # ë¦¬ë·° ë°ì´í„° ìƒì„± (rank ê¸°ë°˜)
            rank = original.get("rank", 999)
            reviews = generate_review_data(rank)
            
            # ê°€ê²© ì •ë³´ êµ¬ì„±
            current_price = original.get("lprice", 0)
            discount_data = processed_data.get("discount")
            
            price_info = {
                "current": current_price,
                "currency": "KRW"
            }
            
            # í• ì¸ ì •ë³´ ì¶”ê°€ (ì œëª©ì—ì„œ ì¶”ì¶œëœ ê²½ìš°ë§Œ)
            if discount_data and discount_data.get("fromTitle"):
                price_info["discount"] = {
                    "fromTitle": True,
                    "type": discount_data.get("type"),
                    "rate": discount_data.get("rate"),
                    "amount": discount_data.get("amount"),
                    "originalText": discount_data.get("originalText")
                }
                
                # ì›ê°€ ì—­ì‚° (í• ì¸ìœ¨ ìˆëŠ” ê²½ìš°)
                if discount_data.get("type") == "rate" and discount_data.get("rate"):
                    rate = discount_data["rate"]
                    if rate > 0 and rate < 100:  # ìœ íš¨ì„± ê²€ì‚¬
                        estimated_original = int(current_price / (1 - rate / 100))
                        price_info["discount"]["estimatedOriginal"] = estimated_original
                
                # í• ì¸ ê¸ˆì•¡ ìˆëŠ” ê²½ìš°
                elif discount_data.get("type") == "amount" and discount_data.get("amount"):
                    estimated_original = current_price + discount_data["amount"]
                    price_info["discount"]["estimatedOriginal"] = estimated_original
            
            # ìƒˆ ë¬¸ì„œ ìƒì„±
            new_doc = {
                "_id": product_id,
                
                # ìƒí’ˆëª… (ì›ë³¸ ê·¸ëŒ€ë¡œ!)
                "name": original.get("title", ""),
                
                # ê°€ê²© (í• ì¸ ì •ë³´ í¬í•¨)
                "price": price_info,
                
                # íŒë§¤ì
                "seller": {
                    "name": original.get("mallName", ""),
                    "type": processed_data.get("sellerType", "general")
                },
                
                # ë¸Œëœë“œ (LLM í‘œì¤€í™”)
                "brand": processed_data.get("brand", original.get("brand", "")),
                
                # ì´ë¯¸ì§€ (ë„¤ì´ë²„ URL ê·¸ëŒ€ë¡œ)
                "images": {
                    "thumbnail": original.get("image", ""),
                    "detail": []
                },
                
                # ì˜µì…˜ (ë¹„ì›Œë‘ )
                "options": [],
                
                # ì¹´í…Œê³ ë¦¬
                "category": {
                    "path": processed_data.get("categoryPath", []),
                    "original": {
                        "category1": original.get("category1"),
                        "category2": original.get("category2"),
                        "category3": original.get("category3"),
                        "category4": original.get("category4")
                    }
                },
                
                # ì„¤ëª…
                "description": {
                    "summary": processed_data.get("summary", ""),
                    "detail": ""
                },
                
                # ê²€ìƒ‰ ë©”íƒ€ë°ì´í„°
                "searchKeywords": processed_data.get("searchKeywords", {
                    "tags": [],
                    "targetAudience": [],
                    "useCase": [],
                    "seasonality": [],
                    "features": []
                }),
                
                # ì¬ê³  (ê¸°ë³¸ true)
                "stock": {
                    "available": True
                },
                
                # ë¦¬ë·° (rank ê¸°ë°˜ ìƒì„±!)
                "reviews": reviews,
                
                # ì›ë³¸ ë°ì´í„° ë³´ì¡´
                "source": {
                    "provider": "naver",
                    "productId": original.get("productId"),
                    "rank": rank,
                    "searchKeyword": original.get("search_keyword"),
                    "originalTitle": original.get("title"),
                    "link": original.get("link")
                },
                
                # ìƒíƒœ
                "status": {
                    "processed": True,
                    "published": True
                },
                
                # íƒ€ì„ìŠ¤íƒ¬í”„
                "createdAt": datetime.utcnow(),
                "updatedAt": datetime.utcnow()
            }
            
            # Dry run ëª¨ë“œ
            if dry_run:
                print(f"âœ“ [{idx}/{total}] {original.get('title', '')[:50]}...")
                if idx == 1:  # ì²« ë²ˆì§¸ ìƒí’ˆë§Œ ìì„¸íˆ ì¶œë ¥
                    print(f"  â†’ ìƒ˜í”Œ ë°ì´í„°:")
                    print(f"     name: {new_doc['name'][:50]}...")
                    print(f"     price: {new_doc['price']}")
                    print(f"     reviews: {new_doc['reviews']}")
                    print(f"     category: {new_doc['category']['path']}")
            else:
                # ì‹¤ì œ ì €ì¥
                products_processed.replace_one(
                    {"_id": product_id},
                    new_doc,
                    upsert=True
                )
                
                if idx % 100 == 0:
                    print(f"âœ“ [{idx}/{total}] ì²˜ë¦¬ ì¤‘...")
            
            success_count += 1
            
        except Exception as e:
            print(f"âŒ [{idx}/{total}] ì˜¤ë¥˜ ({item.get('id', 'unknown')}): {e}")
            error_count += 1
    
    print(f"\n{'=' * 60}")
    print(f"{'[DRY RUN] ' if dry_run else ''}ì™„ë£Œ!")
    print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {error_count}ê°œ")
    print(f"{'=' * 60}\n")


def import_all_processed_batches(input_dir: str, db, dry_run=False):
    """processed ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  JSON íŒŒì¼ ì²˜ë¦¬"""
    
    if not os.path.exists(input_dir):
        print(f"âŒ ë””ë ‰í† ë¦¬ ì—†ìŒ: {input_dir}")
        return
    
    # JSON íŒŒì¼ ëª©ë¡
    files = sorted([
        f for f in os.listdir(input_dir) 
        if f.endswith('.json')
    ])
    
    if not files:
        print(f"âŒ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
        return
    
    print("=" * 60)
    print(f"ğŸ“ ì²˜ë¦¬í•  íŒŒì¼: {len(files)}ê°œ")
    print("=" * 60)
    
    # ì‚¬ìš©ì í™•ì¸
    if not dry_run:
        response = input(f"\nproducts_v2 ì»¬ë ‰ì…˜ì— ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if response.lower() != 'y':
            print("âŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
    
    total_success = 0
    total_error = 0
    
    for idx, filename in enumerate(files, 1):
        print(f"\n{'=' * 60}")
        print(f"[{idx}/{len(files)}] {filename}")
        print(f"{'=' * 60}")
        
        file_path = os.path.join(input_dir, filename)
        import_processed_batch(file_path, db, dry_run)
    
    print(f"\n{'ğŸ‰ ' * 20}")
    print(f"ì „ì²´ ì‘ì—… ì™„ë£Œ!")
    print(f"{'ğŸ‰ ' * 20}\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="LLM ê°€ê³µ ë°ì´í„° MongoDB ì„í¬íŠ¸")
    parser.add_argument("--input-dir", type=str, default="./data_batches/processed", 
                        help="processed ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    parser.add_argument("--file", type=str, help="ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬")
    parser.add_argument("--dry-run", action="store_true", 
                        help="ì‹¤ì œ ì €ì¥í•˜ì§€ ì•Šê³  í…ŒìŠ¤íŠ¸ë§Œ")
    
    args = parser.parse_args()
    
    # MongoDB ì—°ê²°
    mongodb_url = os.getenv("MONGODB_URL", "mongodb://localhost:27017")
    db_name = os.getenv("MONGODB_DB_NAME", "ecommerce_ai")
    
    client = MongoClient(mongodb_url)
    db = client[db_name]
    
    if args.file:
        # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
        import_processed_batch(args.file, db, args.dry_run)
    else:
        # ì „ì²´ ë””ë ‰í† ë¦¬ ì²˜ë¦¬
        import_all_processed_batches(args.input_dir, db, args.dry_run)
